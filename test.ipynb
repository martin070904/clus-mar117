{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: STATS 3DA3\n",
    "subtitle: Homework Assignment 6\n",
    "author: \"Hongrui Chen 400313212\"\n",
    "date: 03/24/2025\n",
    "format: pdf\n",
    "header-includes:\n",
    "   - \\usepackage{amsmath}\n",
    "   - \\usepackage{bbm}\n",
    "   - \\usepackage{array}\n",
    "   - \\usepackage{multirow}\n",
    "   - \\usepackage{graphicx}\n",
    "   - \\usepackage{float}\n",
    "   - \\usepackage{apacite}\n",
    "   - \\usepackage{natbib}\n",
    "execute: \n",
    "  echo: true\n",
    "fontsize: 11pt\n",
    "geometry: margin = 1in\n",
    "linestretch: 1.5\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = heart_disease.data.original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define and describe a classification problem using the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable is ‘num’, which is the diagnosis of heart disease. We need to build a classification model to predict the diagnosis of heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Apply any chosen data transformations, or explain why no transformations were necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=all.copy()\n",
    "all_cate=all[['sex','cp','fbs','restecg','exang','slope','thal']]\n",
    "all_cate = pd.get_dummies(all_cate, columns=all_cate.columns, drop_first=False)\n",
    "all_num = all[['age','trestbps','chol','thalach','oldpeak','ca']]\n",
    "scale = StandardScaler()\n",
    "all_std = pd.DataFrame(\n",
    "    scale.fit_transform(all_num), columns=all_num.columns\n",
    "    ) \n",
    "all_transed=pd.concat([all_cate,all_std], axis = 1)\n",
    "#GitHub Copilot is used in this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Provide a detailed description of the dataset, including variables, summaries, number of observations, data types, and distributions (include at least three statements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name     role         type demographic  \\\n",
      "0        age  Feature      Integer         Age   \n",
      "1        sex  Feature  Categorical         Sex   \n",
      "2         cp  Feature  Categorical        None   \n",
      "3   trestbps  Feature      Integer        None   \n",
      "4       chol  Feature      Integer        None   \n",
      "5        fbs  Feature  Categorical        None   \n",
      "6    restecg  Feature  Categorical        None   \n",
      "7    thalach  Feature      Integer        None   \n",
      "8      exang  Feature  Categorical        None   \n",
      "9    oldpeak  Feature      Integer        None   \n",
      "10     slope  Feature  Categorical        None   \n",
      "11        ca  Feature      Integer        None   \n",
      "12      thal  Feature  Categorical        None   \n",
      "13       num   Target      Integer        None   \n",
      "\n",
      "                                          description  units missing_values  \n",
      "0                                                None  years             no  \n",
      "1                                                None   None             no  \n",
      "2                                                None   None             no  \n",
      "3   resting blood pressure (on admission to the ho...  mm Hg             no  \n",
      "4                                   serum cholestoral  mg/dl             no  \n",
      "5                     fasting blood sugar > 120 mg/dl   None             no  \n",
      "6                                                None   None             no  \n",
      "7                         maximum heart rate achieved   None             no  \n",
      "8                             exercise induced angina   None             no  \n",
      "9   ST depression induced by exercise relative to ...   None             no  \n",
      "10                                               None   None             no  \n",
      "11  number of major vessels (0-3) colored by flour...   None            yes  \n",
      "12                                               None   None            yes  \n",
      "13                         diagnosis of heart disease   None             no  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(heart_disease.variables)\n",
    "all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14 features and 303 observations in the dataset. For the predictor variables, 'sex','cp','fbs','restecg','exang','slope','thal' are categorical variables, 'age','trestbps','chol','thalach','oldpeak','ca' are numerical variables. And there are some missing value in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Transform the response `num` into a binary outcome: `1` for heart disease and `0` for no heart disease. So combine 1, 2, 3, and 4 into `1` and 0 for `0`. For Questions 4-16, use the transformed binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transed['num'] = all['num'].apply(lambda i: 1 if i > 0 else 0)\n",
    "all_transed['num'] = pd.Categorical(all_transed['num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Analyze relationships between variables and discuss their implications for feature selection or extraction (include at least two statements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Drop the rows with the missing values. How many osbervations after dropping the missing values. Skip the outlier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 26)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transed=all_transed.dropna()\n",
    "all_transed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 299 observations after dropping the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Sub-group analysis: Explore potential sub-groups within the data using appropriate data science methods. Identify and visualize these sub-groups without using the labels and categorical variables. Categroical variables already define sub groups so we don't need to include them for this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Split 30% of the data for testing using a random seed of 1. Use the remaining 70% for training and model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_transed.drop(['num'], axis=1)\n",
    "y = all_transed['num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Identify the two classifiers you have chosen. Justify your selections based on the classifier requirement for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing the classification model, so we may try to use the KNN and logistic regression model. Both models are well suited for binary classification tasks and are widely used in classification problems. And logistic regression is the linear, and KNN is non-linear, so we will use two different types of classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Specify two metrics to compare classifier performance. Provide technical details on how each metric is computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Train two selected classifiers in (9) and identify optimal tuning parameters (if applicable) using the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Apply a feature selection or extraction method to one of the classifiers in (9). Train this third classifier on the training set and identify optimal tuning parameters (if applicable) using the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Use the selected metrics to evaluate three classifiers in (11) and (12) on the test set.\n",
    "    - Discuss your findings (at least two statements).\n",
    "    - Discuss the impact of feature selection or extraction on the performance of the classifier (at least one statement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. For the best interpretable model identified in (13), analyze and interpret the most important predictor variables in the context of the classification challenge (at least two statements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. **[Bonus]** Sub-group improvement strategy: If sub-groups were identified, propose and implement a method to further improve the performance of **one** classifier. Compare the fourth classifier performance with the results from (13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. **Team Contributions:** Document each team member’s specific contributions to the questions above. For group submissions, this should match the GitHub commit history. Individual submissions do not need to address this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. **Link** to the public GitHub repository. This is optional for the individual submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Data Science Handbook by Jake VanderPlas (O'Reilly Media, Inc., Published on Nov 21, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Janosi, A., Steinbrunn, W., Pfisterer, M., & Detrano, R. (1989). Heart Disease [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C52P4X."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
